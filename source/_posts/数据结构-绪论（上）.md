---
title: 数据结构 - 绪论（上）
tags:
  - 数据结构
mathjax: true
date: 2018-10-09 17:05:38
---


## 计算

本课程需要研究在计算的过程中所蕴含的本质的内在**规律**，总结和挖掘出其中的一般性方法以及典型**技巧**，实现**高效**的计算，同时也要在资源的消耗方面做到足够的**低廉**。

Dijkstra 说：所谓的计算机，无非是我们的一个工具和手段，而计算才是最终的研究目的和目标。

> Computer science should be called computing science, for the same reason why surgery is not called knife science.
> \- E. Dijkstra

<!-- more -->

### 算法

所谓算法，即特定计算机模型下，旨在解决特定问题的指令序列。
- 输入：待处理的信息（问题）；
- 输出：经处理的信息（答案）；
- 正确性：的确可以解决指定的问题；
- 确定性：任一算法都可以描述为一个由基本操作组成的序列；
- 可行性：每一基本操作都可实现，且在常数时间内完成；
- 有穷性：对于任何输入，经有穷次基本操作，都可以得到输出；

程序未必是算法，例如遇到死循环，但有穷性作为一个侧面要求，并不能简单确定（参考[停机问题](https://zh.wikipedia.org/wiki/%E5%81%9C%E6%9C%BA%E9%97%AE%E9%A2%98)），本课程不做深入探讨。

### 好算法

- 正确：能够编译，并处理各种合法的输入
- 健壮：对不合适输入做适当处理
- 可读：结构化 + 准确命名 + 注释 + …
- **效率**：速度尽可能快；存储空间尽可能少

> 算法 + 数据结构 = 程序
> (算法 + 数据结构) * 效率 = 计算


## 计算模型

### 性能测度

计算是数据结构和算法的有机结合，所以笼统地称之为 `DSA` (Data Structure + Algorithm)。
其好坏优劣是从它的效率而言的，实际应用中就需要能够定量地度量。

> To measure is to know.
> If you can not  measure it, you can not improve it.
> \- Lord kelvin

### 问题规模

成本：运行时间 + 所需存储空间，问题实例的规模，往往是决定计算成本的主要因素。
通常问题规模接近，计算成本也接近；问题规模扩大，计算成本也随之上升。

### 最坏情况

同一问题等规模的不同实例，计算成本也不尽相同，甚至有实质差别。
所以，在规模同为 n 的所有实例中，只关注最坏情况。

### 理想模型

实验统计最直接，但不足以准确反映算法的真正效率
- 不同的算法，可能更适应不同**规模**的输入；
- 不同的算法，可能更适应不同**类型**的输入；
- 同一算法，可能由于不同**程序员**、用不同程序**语言**、经不同**编译器**实现；
- 同一算法，可能实现并运行于不同的**体系架构**、**操作系统**…

所以需要抽象出一个**理想**的平台或模型，不再依赖上述种种具体的因素，给出**客观**的评判。

### 图灵机

参考：[图灵机](https://zh.wikipedia.org/wiki/%E5%9B%BE%E7%81%B5%E6%9C%BA)

### RAM 模型

RAM: Random Access Machine

- 寄存器顺序编号，总数没有限制
- 每一基本操作仅需常数时间
```
R[i] <- c
R[i] <- R[R[j]]
R[i] <- R[j] + R[k]
R[i] <- R[j]
R[R[i]] <- R[j]
R[i] <- R[j] - R[k]
IF R[i] = 0 GOTO 1
IF R[i] > 0 GOTO 1
GOTO 1
STOP
```

在这些模型中，算法的运行时间与执行的基本操作次数正相关。

这里是一个向下取整除法的 `RAM` 实例，用 `c` 除以 `d`：
```
R[3] <- 1
R[0] <- R[0] + R[3]		// R[0] = c + 1
R[0] <- R[0] - R[1]		// c -= d
R[2] <- R[2] + R[3]		// x += 1
IF R[0] > 0 GOTO 3		// IF c > 0 GOTO 3
R[0] <- R[2] - R[3]		// ELSE x -= 1
STOP				// RETURN  R[0] = x
```

对于一个 12 除以 5 的计算实例，对寄存器作一罗列后，最终得到了结果 2

Step | IR | R[0] | R[1] | R[2] | R[3]
:-: | :-: | :-: | :-: | :-: | :-:
0 | 0 | 12 | 5 | 0 | 0
1 | 1 | ^ | ^ | ^ | 1
2 | 2 | 13 | ^ | ^ | ^
3 | 3 | 8 | ^ | ^ | ^
4 | 4 | ^ | ^ | 1 | ^
5 | 2 | ^ | ^ | ^ | ^
6 | 3 | 3 | ^ | ^ | ^
7 | 4 | ^ | ^ | 2 | ^
8 | 2 | ^ | ^ | ^ | ^
9 | 3 | 0 | ^ | ^ | ^
10 | 4 | ^ | ^ | 3 | ^
11 | 5 | ^ | ^ | ^ | ^
12 | 6 | 2 | ^ | ^ | ^

表格的行数，就是执行的基本操作次数，即性能的度量。


## 大 O 记号

对于算法，更关注其主要的、长远的变化趋势，而不是局部的，细微的，暂时的趋势。
当 n 足够大时，通过大 O 记号更加简洁地反映算法的时间或空间复杂度。
- 常系数可以忽略：$O(f(n)) = O(c \times f(n))$
- 低次项可以忽略：$O(n^a + n^b) = O(n^a), a > b > 0$

大 O 记号表示了复杂度的上界，另外还有 $\Omega$ 和 $\Theta$ 分别表示复杂度的下界和确界。

{% img /images/DSA/C1-1.png %}

### 高效解

#### 常数 $ O(1) $

表示常数复杂度，是最好的复杂度了，通常是不含转向（循环、调用、递归等）顺序执行的代码。
$$ 2 = 2013 = 2013 \times 2013 = 2013 ^ {2013} = O(1) $$

#### 对数 $ O(log^c n) $

这类算法非常有效，复杂度无限接近于常数。
$$ lnn | lgn | log_{100} n | log_{2013} n = O(logn) $$

- 常底数无所谓
$$ log_a n = log_a b \times log_b n = \Theta(log_b n) $$
- 常数次幂无所谓
$$ logn^c = c \cdot logn = \Theta(log n) $$
- 对数多项式忽略低次项
$$ 123 * log^{321} n + log^{105}(n^2 - n + 1) = \Theta(log^{321} n) $$

### 有效解

#### 多项式 $ O(n^c) $

编程习题主要覆盖的范围都是从 $ O(n) $ 到 $ O(n^2) $。
这类算法的效率通常认为已可令人满意，可解而至少不是难解。

### 难解

#### 指数 $ O(2^n) $

这类算法的计算成本增长极快，通常认为不可忍受。
从 $ O(n^c) $ 到 $ O(2^n) $，是从有效算法到无效算法的分水岭。
很多问题的 $ O(2^n) $ 算法往往显而易见，然而设计出 $ O(n^c) $ 算法却及其不易。


## 总结

- 所谓算法，即特定计算机模型下，旨在解决特定问题的指令序列。
- 好算法最重要的是：速度尽可能快；存储空间尽可能少。
- 通常使用图灵机或者寄存器模型，大 O 记号通过大规模输入对算法进行评估。
- 算法的效率：$ O(1) > O(log^c n) > O(n^c) > O(2^n) $